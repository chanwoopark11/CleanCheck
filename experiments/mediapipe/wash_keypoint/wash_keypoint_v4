import cv2
import mediapipe as mp
import numpy as np
import time
from ultralytics import YOLO

# =================================================================================
# 1. 설정 및 상수
# =================================================================================
YOLO_MODEL_PATH = r"D:\Download\best (2).pt"
YOLO_CONF_THRESHOLD = 0.6
CONTACT_TIME_THRESHOLD = 0.5
UNWASHED_COLOR = (0, 0, 255)
PALM_WASHED_COLOR = (0, 255, 0)
BACK_WASHED_COLOR = (255, 165, 0)
TEXT_COLOR = (255, 255, 255)
ORIENTATION_CONFIRM_FRAMES = 5

# [속도 개선] YOLO 연산을 몇 프레임마다 한 번씩 실행할지 결정합니다. (값이 클수록 빠르지만 반응은 느려짐)
YOLO_INFERENCE_INTERVAL = 3

# =================================================================================
# 2. 유틸리티 및 핵심 로직 함수
# =================================================================================

mp_hands = mp.solutions.hands

def estimate_palm_direction(landmarks, label):
    if not landmarks or not (0 in landmarks and 5 in landmarks and 17 in landmarks):
        return True 
    
    wrist = np.array(landmarks[0])
    index_mcp = np.array(landmarks[5])
    pinky_mcp = np.array(landmarks[17])

    v1 = index_mcp - wrist
    v2 = pinky_mcp - wrist

    normal = np.cross(np.append(v1, 0), np.append(v2, 0))

    if label == "Left":
        return normal[2] < 0 
    else: # Right hand
        return normal[2] > 0 

def create_kalman_filter(x, y):
    kf = cv2.KalmanFilter(4, 2)
    kf.transitionMatrix = np.array([[1, 0, 1, 0],
                                     [0, 1, 0, 1],
                                     [0, 0, 1, 0],
                                     [0, 0, 0, 1]], np.float32)
    kf.measurementMatrix = np.eye(2, 4, dtype=np.float32)
    kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03
    kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.5
    kf.statePost = np.array([[x], [y], [0], [0]], dtype=np.float32)
    return kf

def update_kalman_filters(kalman_dict, detection):
    predicted = {}
    if detection:
        for idx, (cx, cy) in detection.items():
            if idx not in kalman_dict:
                kalman_dict[idx] = create_kalman_filter(cx, cy)
            
            kf = kalman_dict[idx]
            kf.predict()
            kf.correct(np.array([[np.float32(cx)], [np.float32(cy)]]))
            
            predicted[idx] = (int(kf.statePost[0]), int(kf.statePost[1]))
    return predicted

cleansed_state = {}
contact_timers = {}
stable_orientations = {}
orientation_counters = {}
active_scenario_global = 0 

last_known_landmarks_prev_frame = {"Left": None, "Right": None}

def reset_wash_status():
    global cleansed_state, contact_timers, stable_orientations, orientation_counters, active_scenario_global, last_known_landmarks_prev_frame
    cleansed_state = {
        "Left": {"palm": [False]*21, "back": [False]*21},
        "Right": {"palm": [False]*21, "back": [False]*21}
    }
    contact_timers = {
        "Left": {"palm": [0]*21, "back": [0]*21},
        "Right": {"palm": [0]*21, "back": [0]*21}
    }
    stable_orientations = {"Left": "palm", "Right": "palm"}
    orientation_counters = {"Left": 0, "Right": 0}
    active_scenario_global = 0
    last_known_landmarks_prev_frame = {"Left": None, "Right": None}

def calculate_movement_magnitude(current_landmarks, previous_landmarks):
    if not current_landmarks or not previous_landmarks:
        return 0.0
    
    total_movement = 0.0
    for idx in current_landmarks:
        if idx in previous_landmarks:
            curr_x, curr_y = current_landmarks[idx]
            prev_x, prev_y = previous_landmarks[idx]
            total_movement += np.sqrt((curr_x - prev_x)**2 + (curr_y - prev_y)**2)
    return total_movement

def update_cleansed_status(pred_left, pred_right, facing_left_is_palm, facing_right_is_palm, current_action):
    global active_scenario_global, last_known_landmarks_prev_frame
    now = time.time()
    
    if not pred_left or not pred_right:
        for i in range(21):
            for hand in ["Left", "Right"]:
                for side in ["palm", "back"]: contact_timers[hand][side][i] = 0
        active_scenario_global = 0
        last_known_landmarks_prev_frame["Left"] = pred_left
        last_known_landmarks_prev_frame["Right"] = pred_right
        return
    
    left_points = np.array(list(pred_left.values()), dtype=np.int32)
    right_points = np.array(list(pred_right.values()), dtype=np.int32)
    left_hull = cv2.convexHull(left_points) if len(left_points) >= 3 else None
    right_hull = cv2.convexHull(right_points) if len(right_points) >= 3 else None
    
    if left_hull is None or right_hull is None: 
        for i in range(21):
            for hand in ["Left", "Right"]:
                for side in ["palm", "back"]: contact_timers[hand][side][i] = 0
        active_scenario_global = 0
        last_known_landmarks_prev_frame["Left"] = pred_left
        last_known_landmarks_prev_frame["Right"] = pred_right
        return

    if current_action == 0 or current_action == 2:
        active_scenario_global = 1
        for i, point_left in pred_left.items():
            is_in_contact = cv2.pointPolygonTest(right_hull, point_left, False) >= 0
            if is_in_contact:
                if contact_timers["Left"]["palm"][i] == 0: contact_timers["Left"]["palm"][i] = now
                contact_timers["Left"]["back"][i] = 0 
                if now - contact_timers["Left"]["palm"][i] > CONTACT_TIME_THRESHOLD: 
                    cleansed_state["Left"]["palm"][i] = True
            else: 
                contact_timers["Left"]["palm"][i] = 0
                contact_timers["Left"]["back"][i] = 0

        for i, point_right in pred_right.items():
            is_in_contact = cv2.pointPolygonTest(left_hull, point_right, False) >= 0
            if is_in_contact:
                if contact_timers["Right"]["palm"][i] == 0: contact_timers["Right"]["palm"][i] = now
                contact_timers["Right"]["back"][i] = 0 
                if now - contact_timers["Right"]["palm"][i] > CONTACT_TIME_THRESHOLD: 
                    cleansed_state["Right"]["palm"][i] = True
            else: 
                contact_timers["Right"]["palm"][i] = 0
                contact_timers["Right"]["back"][i] = 0

    elif current_action == -1 and pred_left and pred_right:
        if (facing_left_is_palm and not facing_right_is_palm) or \
           (not facing_left_is_palm and facing_right_is_palm):
            active_scenario_global = 2
            
            for i, point_left in pred_left.items():
                is_in_contact = cv2.pointPolygonTest(right_hull, point_left, False) >= 0
                if is_in_contact:
                    if contact_timers["Left"]["palm"][i] == 0: contact_timers["Left"]["palm"][i] = now
                    contact_timers["Left"]["back"][i] = 0 
                    if now - contact_timers["Left"]["palm"][i] > CONTACT_TIME_THRESHOLD: 
                        cleansed_state["Left"]["palm"][i] = True
                else: 
                    contact_timers["Left"]["palm"][i] = 0
                    contact_timers["Left"]["back"][i] = 0

            for i, point_right in pred_right.items():
                is_in_contact = cv2.pointPolygonTest(left_hull, point_right, False) >= 0
                if is_in_contact:
                    if contact_timers["Right"]["palm"][i] == 0: contact_timers["Right"]["palm"][i] = now
                    contact_timers["Right"]["back"][i] = 0 
                    if now - contact_timers["Right"]["palm"][i] > CONTACT_TIME_THRESHOLD: 
                        cleansed_state["Right"]["palm"][i] = True
                else: 
                    contact_timers["Right"]["palm"][i] = 0
                    contact_timers["Right"]["back"][i] = 0
        
        elif not facing_left_is_palm and not facing_right_is_palm: # 양손이 모두 손등으로 감지된 경우 (시나리오 3 - 특수)
            active_scenario_global = 3 
            
            if last_known_landmarks_prev_frame["Left"] and last_known_landmarks_prev_frame["Right"]:
                left_movement = calculate_movement_magnitude(pred_left, last_known_landmarks_prev_frame["Left"])
                right_movement = calculate_movement_magnitude(pred_right, last_known_landmarks_prev_frame["Right"])

                if left_movement > right_movement:
                    # 왼손은 손바닥 세척, 오른손은 손등 세척
                    for i, point_left in pred_left.items():
                        is_in_contact = cv2.pointPolygonTest(right_hull, point_left, False) >= 0
                        if is_in_contact:
                            if contact_timers["Left"]["palm"][i] == 0: contact_timers["Left"]["palm"][i] = now
                            contact_timers["Left"]["back"][i] = 0 
                            if now - contact_timers["Left"]["palm"][i] > CONTACT_TIME_THRESHOLD: 
                                cleansed_state["Left"]["palm"][i] = True
                        else: 
                            contact_timers["Left"]["palm"][i] = 0
                            contact_timers["Left"]["back"][i] = 0
                    
                    for i, point_right in pred_right.items():
                        is_in_contact = cv2.pointPolygonTest(left_hull, point_right, False) >= 0
                        if is_in_contact:
                            if contact_timers["Right"]["back"][i] == 0: contact_timers["Right"]["back"][i] = now
                            contact_timers["Right"]["palm"][i] = 0 
                            if now - contact_timers["Right"]["back"][i] > CONTACT_TIME_THRESHOLD: 
                                cleansed_state["Right"]["back"][i] = True
                        else: 
                            contact_timers["Right"]["palm"][i] = 0
                            contact_timers["Right"]["back"][i] = 0
                else: # right_movement >= left_movement
                    # 오른손은 손바닥 세척, 왼손은 손등 세척
                    for i, point_left in pred_left.items():
                        is_in_contact = cv2.pointPolygonTest(right_hull, point_left, False) >= 0
                        if is_in_contact:
                            if contact_timers["Left"]["back"][i] == 0: contact_timers["Left"]["back"][i] = now
                            contact_timers["Left"]["palm"][i] = 0 
                            if now - contact_timers["Left"]["back"][i] > CONTACT_TIME_THRESHOLD: 
                                cleansed_state["Left"]["back"][i] = True
                        else: 
                            contact_timers["Left"]["palm"][i] = 0
                            contact_timers["Left"]["back"][i] = 0

                    for i, point_right in pred_right.items():
                        is_in_contact = cv2.pointPolygonTest(left_hull, point_right, False) >= 0
                        if is_in_contact:
                            if contact_timers["Right"]["palm"][i] == 0: contact_timers["Right"]["palm"][i] = now
                            contact_timers["Right"]["back"][i] = 0 
                            if now - contact_timers["Right"]["palm"][i] > CONTACT_TIME_THRESHOLD: 
                                cleansed_state["Right"]["palm"][i] = True
                        else: 
                            contact_timers["Right"]["palm"][i] = 0
                            contact_timers["Right"]["back"][i] = 0
            else: 
                for i in range(21):
                    for hand in ["Left", "Right"]:
                        for side in ["palm", "back"]: contact_timers[hand][side][i] = 0
                active_scenario_global = 3 
        else: # 시나리오 2/3 조건에 맞지 않는 모든 MediaPipe 감지
            active_scenario_global = 3 
            for i in range(21):
                for hand in ["Left", "Right"]:
                    for side in ["palm", "back"]: contact_timers[hand][side][i] = 0
    else: # YOLO가 0, 2 외의 다른 클래스를 감지했거나, 한 손만 감지 등
        active_scenario_global = 3 
        for i in range(21):
            for hand in ["Left", "Right"]:
                for side in ["palm", "back"]: contact_timers[hand][side][i] = 0
    
    last_known_landmarks_prev_frame["Left"] = pred_left
    last_known_landmarks_prev_frame["Right"] = pred_right


def draw_hand_visuals(image, landmarks, label, is_palm):
    if not landmarks:
        return

    overlay = image.copy()
    hull_points = [landmarks[i] for i in range(21) if i in landmarks]
    side = "palm" if is_palm else "back" 

    if len(hull_points) > 2:
        hull = cv2.convexHull(np.array(hull_points, dtype=np.int32))
        
        if label in cleansed_state and side in cleansed_state[label]:
            washed_count = sum(1 for i in range(21) if cleansed_state[label][side][i])
            wash_ratio = washed_count / 21
            if wash_ratio > 0.1:
                color = PALM_WASHED_COLOR if is_palm else BACK_WASHED_COLOR
                alpha = min(0.1 + wash_ratio * 0.6, 0.7)
                cv2.fillConvexPoly(overlay, hull, color)
                cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)

    if label in cleansed_state and side in cleansed_state[label]:
        for i, point in landmarks.items():
            color = (PALM_WASHED_COLOR if is_palm else BACK_WASHED_COLOR) if cleansed_state[label][side][i] else UNWASHED_COLOR
            cv2.circle(image, point, 8, color, -1)
            cv2.circle(image, point, 8, (0, 0, 0), 1)

    if 0 in landmarks:
        label_text = f"{label} - {side.capitalize()}"
        cv2.putText(image, label_text, (landmarks[0][0] - 50, landmarks[0][1] + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_COLOR, 2)

def draw_progress_bar(image, current_action_from_yolo): 
    global active_scenario_global 
    
    total_points = 84 
    washed_points = sum(sum(cleansed_state[hand][side]) for hand in cleansed_state for side in cleansed_state[hand])
    
    progress = washed_points / total_points if total_points > 0 else 0
    bar_width = int((image.shape[1] - 40) * progress)
    
    cv2.rectangle(image, (20, 20), (image.shape[1] - 20, 50), (100, 100, 100), -1) 
    if bar_width > 0: 
        cv2.rectangle(image, (20, 20), (20 + bar_width, 50), (0, 255, 127), -1) 

    cv2.putText(image, f"Wash Progress: {progress:.0%}", (30, 42), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_COLOR, 2)
    cv2.putText(image, "Press 'r' to Reset", (image.shape[1] - 180, image.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    
    action_text = "Action: N/A"

    if active_scenario_global == 1:
        action_text = "Action: Scenario 1 (YOLO Detected)"
    elif active_scenario_global == 2:
        action_text = "Action: Scenario 2 (MediaPipe Directed)"
    elif active_scenario_global == 3:
        action_text = "Action: Scenario 3 (Dynamic Back/Palm Wash)"

    cv2.putText(image, action_text, (20, image.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

# =================================================================================
# 3. 메인 애플리케이션
# =================================================================================
def main():
    try:
        model = YOLO(YOLO_MODEL_PATH)
    except Exception as e:
        print(f"Error loading YOLO model: {e}")
        print(f"Please check if the model path '{YOLO_MODEL_PATH}' is correct and 'ultralytics' is installed.")
        return

    hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)
    
    cap = cv2.VideoCapture(0)
    
    kalman_left, kalman_right = {}, {}
    last_known_landmarks = {"Left": None, "Right": None}
    
    reset_wash_status()

    frame_counter = 0
    current_detected_action = -1 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame = cv2.flip(frame, 1) # 좌우 반전 (거울 모드)
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, _ = frame.shape

        if frame_counter % YOLO_INFERENCE_INTERVAL == 0:
            yolo_results = model(frame, verbose=False)
            
            action_this_frame = -1 
            if yolo_results and yolo_results[0].boxes: 
                boxes = yolo_results[0].boxes
                if len(boxes) > 0:
                    best_box = max(boxes, key=lambda box: box.conf[0])
                    if best_box.conf[0] > YOLO_CONF_THRESHOLD:
                        detected_class = int(best_box.cls[0])
                        action_this_frame = detected_class
            current_detected_action = action_this_frame 
        
        hands_results = hands.process(image_rgb)
        
        # --- [핵심 수정] MediaPipe 손 라벨 보정 로직 ---
        # MediaPipe가 감지한 손 목록을 저장할 임시 리스트
        temp_detected_hands_raw = []
        if hands_results.multi_hand_landmarks:
            for i, hand_landmarks_raw in enumerate(hands_results.multi_hand_landmarks):
                # MediaPipe가 직접 할당한 라벨 (이것이 틀릴 수 있음)
                original_label = hands_results.multi_handedness[i].classification[0].label
                landmarks_pixel = {idx: (int(lm.x * w), int(lm.y * h)) for idx, lm in enumerate(hand_landmarks_raw.landmark)}
                
                # 손목 랜드마크 0의 X-좌표를 기준으로 중심점 찾기
                wrist_x = landmarks_pixel[0][0] if 0 in landmarks_pixel else w / 2 
                
                temp_detected_hands_raw.append({'label': original_label, 'landmarks': landmarks_pixel, 'wrist_x': wrist_x, 'hand_obj': hand_landmarks_raw})
        
        # 두 손이 감지되었을 때만 X-좌표 기반으로 왼손/오른손 재정렬
        detected_hands = {"Left": None, "Right": None}
        if len(temp_detected_hands_raw) == 2:
            # X-좌표가 더 작은 손이 'Left'로, 더 큰 손이 'Right'로 가정 (카메라 기준)
            if temp_detected_hands_raw[0]['wrist_x'] < temp_detected_hands_raw[1]['wrist_x']:
                detected_hands["Left"] = temp_detected_hands_raw[0]['landmarks']
                detected_hands["Right"] = temp_detected_hands_raw[1]['landmarks']
                # stable_orientations도 재정렬된 라벨에 맞춰 업데이트
                if temp_detected_hands_raw[0]['label'] == 'Left':
                    raw_orientation_is_palm_left = estimate_palm_direction(detected_hands["Left"], "Left")
                    raw_orientation_is_palm_right = estimate_palm_direction(detected_hands["Right"], "Right")
                else: # MediaPipe가 라벨을 반대로 할당했을 경우
                    raw_orientation_is_palm_left = estimate_palm_direction(detected_hands["Left"], "Left") # 이 손은 실제로는 Left지만 MediaPipe가 Right로 봤을 수도 있음
                    raw_orientation_is_palm_right = estimate_palm_direction(detected_hands["Right"], "Right") # 이 손은 실제로는 Right지만 MediaPipe가 Left로 봤을 수도 있음

            else:
                detected_hands["Left"] = temp_detected_hands_raw[1]['landmarks']
                detected_hands["Right"] = temp_detected_hands_raw[0]['landmarks']
                # stable_orientations도 재정렬된 라벨에 맞춰 업데이트
                if temp_detected_hands_raw[1]['label'] == 'Left':
                    raw_orientation_is_palm_left = estimate_palm_direction(detected_hands["Left"], "Left")
                    raw_orientation_is_palm_right = estimate_palm_direction(detected_hands["Right"], "Right")
                else: # MediaPipe가 라벨을 반대로 할당했을 경우
                    raw_orientation_is_palm_left = estimate_palm_direction(detected_hands["Left"], "Left")
                    raw_orientation_is_palm_right = estimate_palm_direction(detected_hands["Right"], "Right")
        elif len(temp_detected_hands_raw) == 1: # 한 손만 감지된 경우 (재정렬 필요 없음)
            label = temp_detected_hands_raw[0]['label']
            detected_hands[label] = temp_detected_hands_raw[0]['landmarks']
            
            if label == 'Left':
                raw_orientation_is_palm_left = estimate_palm_direction(detected_hands["Left"], "Left")
                raw_orientation_is_palm_right = None # 오른손 없음
            else: # label == 'Right'
                raw_orientation_is_palm_right = estimate_palm_direction(detected_hands["Right"], "Right")
                raw_orientation_is_palm_left = None # 왼손 없음
        
        # 재정렬된 detected_hands를 사용하여 stable_orientations 업데이트
        for label, landmarks in detected_hands.items():
            if landmarks:
                raw_orientation_is_palm = estimate_palm_direction(landmarks, label)
                is_stable_palm = (stable_orientations[label] == "palm")
                if raw_orientation_is_palm == is_stable_palm: 
                    orientation_counters[label] = 0
                else: 
                    orientation_counters[label] += 1
                
                if orientation_counters[label] > ORIENTATION_CONFIRM_FRAMES:
                    stable_orientations[label] = "palm" if raw_orientation_is_palm else "back"
                    orientation_counters[label] = 0

        # 칼만 필터 업데이트 (재정렬된 detected_hands 사용)
        predicted_left = update_kalman_filters(kalman_left, detected_hands["Left"])
        predicted_right = update_kalman_filters(kalman_right, detected_hands["Right"])
        
        # 마지막으로 알려진 랜드마크 업데이트
        if predicted_left: last_known_landmarks["Left"] = predicted_left
        if predicted_right: last_known_landmarks["Right"] = predicted_right
        
        # 최종적으로 안정된 손 방향 (재정렬된 라벨에 맞춰 사용)
        final_facing_left = (stable_orientations["Left"] == "palm")
        final_facing_right = (stable_orientations["Right"] == "palm")

        # --- 핵심 로직 실행 및 시각화 ---
        update_cleansed_status(last_known_landmarks["Left"], last_known_landmarks["Right"], 
                               final_facing_left, final_facing_right, current_detected_action)
        
        draw_hand_visuals(frame, last_known_landmarks["Left"], "Left", final_facing_left)
        draw_hand_visuals(frame, last_known_landmarks["Right"], "Right", final_facing_right)
        
        draw_progress_bar(frame, current_detected_action) 

        cv2.imshow("Hand Wash Visualizer (Optimized)", frame)

        frame_counter += 1

        key = cv2.waitKey(5) & 0xFF
        if key == ord('q'): 
            break
        if key == ord('r'):
            reset_wash_status()
            frame_counter = 0 

    cap.release()
    hands.close()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
